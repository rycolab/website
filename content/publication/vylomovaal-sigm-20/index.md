---
title: 'SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological Inflection'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
- Ekaterina Vylomova
- Jennifer White
- Elizabeth Salesky
- Sabrina J. Mielke
- Shijie Wu
- Edoardo Maria Ponti
- Rowan Hall Maudslay
- Ran Zmigrod
- Josef Valvoda
- Svetlana Toldova
- Francis Tyers
- Elena Klyachko
- Ilya Yegorov
- Natalia Krizhanovsky
- Paula Czarnowska
- Irene Nikkarinen
- Andrew Krizhanovsky
- Tiago Pimentel
- Lucas Torroba Hennigen
- Christo Kirov
- Garrett Nicolai
- Adina Williams
- Antonios Anastasopoulos
- Hilaria Cruz
- Eleanor Chodroff
- Ryan Cotterell
- Miikka Silfverberg
- Mans Hulden

# Author notes (such as 'Equal Contribution')
author_notes: []

date: '2020-07-01'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2026-02-28T11:03:04.152327Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types:
- '1'

# Publication name and optional abbreviated publication name.
publication: '*Proceedings of the 58th Annual Meeting of the Association for Computational
  Linguistics*'
publication_short: ''

abstract: A broad goal in natural language processing (NLP) is to develop a system
  that has the capacity to process any natural language. Most systems, however, are
  developed using data from just one language such as English. The SIGMORPHON 2020
  shared task on morphological reinflection aims to investigate systemsâ€™ ability to
  generalize across typologically distinct languages, many of which are low resource.
  Systems were developed using data from 45 languages and just 5 language families,
  fine-tuned with data from an additional 45 languages and 10 language families (13
  in total), and evaluated on all 90 languages. A total of 22 systems (19 neural)
  from 10 teams were submitted to the task. All four winning systems were neural (two
  monolingual transformers and two massively multilingual RNN-based models with gated
  attention). Most teams demonstrate utility of data hallucination and augmentation,
  ensembles, and multilingual training for low-resource languages. Non-neural learners
  and manually designed grammars showed competitive and even superior performance
  on some languages (such as Ingrian, Tajik, Tagalog, Zarma, Lingala), especially
  with very limited data. Some language families (Afro-Asiatic, Niger-Congo, Turkic)
  were relatively easy for most systems and achieved over 90% mean accuracy while
  others were more challenging.

# Summary. An optional shortened abstract.
summary: ''

tags: []

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
venue: SIGMORPHON
links:
- name: URL
  url: https://arxiv.org/abs/2006.11572
---

Add the **full text** or **supplementary notes** for the publication here using Markdown formatting.
