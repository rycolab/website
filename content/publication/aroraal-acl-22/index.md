---
title: Estimating the Entropy of Linguistic Distributions
date: '2022-05-01'
publishDate: '2023-07-09T14:51:05.543137Z'
authors:
- Aryaman Arora
- Clara Meister
- Ryan Cotterell
publication_types:
- '1'
abstract: Shannon entropy is often a quantity of interest to linguists studying the
  communicative capacity of human language. However, entropymust typically be estimated
  from observed data because researchers do not have access to the underlying probability
  distribution. While entropy estimation is a well-studied problem in other fields,
  there is not yet a comprehensive exploration of the efficacy of entropy estimators
  for use with linguistic data. In this work, we fill this void, studying the empirical
  effectiveness of different entropy estimators for linguistic distributions. In a
  replication of two recent information-theoretic linguistic studies, we find evidence
  that the reported effect size is over-estimated due to over-reliance on poor entropy
  estimators. We end this paper with a concrete recommendation for the entropy estimators
  that should be used in future linguistic studies.
featured: false
publication: '*Proceedings of the 60th Annual Meeting of the Association for Computational
  Linguistics (Volume 1: Long Papers)*'
links:
- name: URL
  url: https://arxiv.org/abs/2204.01469
url_pdf: papers/arora+al.acl22.pdf
---

