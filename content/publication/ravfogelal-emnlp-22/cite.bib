@inproceedings{ravfogel+al.emnlp22,
 abstract = {One prominent approach for the identification of concepts in neural representations is searching for a linear subspace whose erasure prevents the prediction of the concept from the representations. However, while many linear erasure algorithms are tractable and interpretable, neural networks do not necessarily represent concepts in a linear manner. To identify non-linearly encoded concepts, we propose a kernelization of a linear minimax game for concept erasure. We demonstrate that it is possible to prevent specific non-linear adversaries from predicting the concept. However, the protection does not transfer to different nonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded concept remains an open problem.},
 address = {Abu Dhabi, United Arab Emirates},
 arxiv = {https://arxiv.org/abs/2201.12191},
 author = {Ravfogel, Shauli and 
Vargas, Francisco and 
Goldberg, Yoav and 
Cotterell, Ryan},
 booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
 code = {https://github.com/shauli-ravfogel/adv-kernel-removal},
 month = {December},
 publisher = {Association for Computational Linguistics},
 title = {Kernelized Concept Erasure},
 url = {https://arxiv.org/abs/2201.12191},
 venue = {EMNLP},
 year = {2022}
}
