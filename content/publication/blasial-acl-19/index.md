---
title: 'On the distribution of deep clausal embeddings: A large cross-linguistic study'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
- Damián Blasi
- Ryan Cotterell
- Lawrence Wolf-Sonkin
- Sabine Stoll
- Balthasar Bickel
- Marco Baroni

# Author notes (such as 'Equal Contribution')
author_notes: []

date: '2019-07-01'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2026-02-28T11:03:10.353685Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types:
- '1'

# Publication name and optional abbreviated publication name.
publication: '*Proceedings of the 57th Annual Meeting of the Association for Computational
  Linguistics*'
publication_short: ''

abstract: 'Embedding a clause inside another (``the girl [who likes cars [that run
  fast]] has arrived″) is a fundamental resource that has been argued to be a key
  driver of linguistic expressiveness. As such, it plays a central role in fundamental
  debates on what makes human language unique, and how they might have evolved. Empirical
  evidence on the prevalence and the limits of embeddings has however been based on
  either laboratory setups or corpus data of relatively limited size. We introduce
  here a collection of large, dependency-parsed written corpora in 17 languages, that
  allow us, for the first time, to capture clausal embedding through dependency graphs
  and assess their distribution. Our results indicate that there is no evidence for
  hard constraints on embedding depth: the tail of depth distributions is heavy. Moreover,
  although deeply embedded clauses tend to be shorter, suggesting processing load
  issues, complex sentences with many embeddings do not display a bias towards less
  deep embeddings. Taken together, the results suggest that deep embeddings are not
  disfavoured in written language. More generally, our study illustrates how resources
  and methods from latest-generation big-data NLP can provide new perspectives on
  fundamental questions in theoretical linguistics.'

# Summary. An optional shortened abstract.
summary: ''

tags: []

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
venue: ACL
---

Add the **full text** or **supplementary notes** for the publication here using Markdown formatting.
