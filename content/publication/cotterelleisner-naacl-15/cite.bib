@inproceedings{cotterell+eisner.naacl15,
 title = {Penalized Expectation Propagation for Graphical Models over Strings},
 author = {Cotterell, Ryan and 
Eisner, Jason},
 booktitle = {Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 month = {July},
 year = {2015},
 address = {Denver, Colorado},
 publisher = {Association for Computational Linguistics},
 pages = {932--942},
 url = {https://www.aclweb.org/anthology/N15-1094.pdf},
 abstract = {We present penalized expectation propagation (PEP), a novel algorithm for approximate inference in graphical models. Expectation propagation is a variant of loopy belief propagation that keeps messages tractable by projecting them back into a given family of functions. Our extension, PEP, uses a structuredsparsity penalty to encourage simple messages, thus balancing speed and accuracy. We specifically show how to instantiate PEP in the case of string-valued random variables, where we adaptively approximate finite-state distributions by variable-order n-gram models. On phonological inference problems, we obtain substantial speedup over previous related algorithms with no significant loss in accuracy.}
}

