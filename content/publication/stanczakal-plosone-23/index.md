---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models
subtitle: ''
summary: ''
authors:
- Karolina Sta≈Ñczak
- Sagnik Ray Choudhury
- Tiago Pimentel
- Ryan Cotterell
- Isabelle Augenstein
tags: []
categories: []
date: '2023-01-01'
lastmod: 2023-12-20T23:53:31+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-12-20T23:16:50.208041Z'
publication_types:
- '0'
abstract: While the prevalence of large pre-trained language models has led to significant
  improvements in the performance of NLP systems, recent research has demonstrated
  that these models inherit societal biases extant in natural language. In this paper,
  we explore a simple method to probe pre-trained language models for gender bias,
  which we use to effect a multi-lingual study of gender bias towards politicians.
  We construct a dataset of 250k politicians from most countries in the world and
  quantify adjective and verb usage around those politicians' names as a function
  of their gender. We conduct our study in 7 languages across 6 different language
  modeling architectures. Our results demonstrate that stance towards politicians
  in pre-trained language models is highly dependent on the language used. Finally,
  contrary to previous findings, our study suggests that larger language models do
  not tend to be significantly more gender-biased than smaller ones.
publication: ''
links:
- name: URL
  url: https://arxiv.org/abs/2104.07505
---
