---
title: On Affine Homotopy between Language Encoders

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
- Robin S. M. Chan
- Reda Boumasmoud
- Anej Svete
- Yuxin Ren
- Qipeng Guo
- Zhijing Jin
- Shauli Ravfogel
- Mrinmaya Sachan
- Bernhard Sch√∂lkopf
- Mennatallah El-Assady
- Ryan Cotterell

# Author notes (such as 'Equal Contribution')
author_notes: []

date: '2024-12-01'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2026-02-28T10:51:40.924097Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types:
- '1'

# Publication name and optional abbreviated publication name.
publication: '*Advances in Neural Information Processing Systems 38 (2024)*'
publication_short: ''

abstract: 'Pre-trained language encoders---functions that represent text as vectors---are
  an integral component of many NLP tasks. We tackle a natural question in language
  encoder analysis: What does it mean for two encoders to be similar? We contend that
  a faithful measure of similarity needs to be emphintrinsic, that is, task-independent,
  yet still be informative of emphextrinsic similarity---the performance on downstream
  tasks. It is common to consider two encoders similar if they are emphhomotopic,
  i.e., if they can be aligned through some transformation. In this spirit, we study
  the properties of emphaffine alignment of language encoders and its implications
  on extrinsic similarity. We find that while affine alignment is fundamentally an
  asymmetric notion of similarity, it is still informative of extrinsic similarity.
  We confirm this on datasets of natural language representations. Beyond providing
  useful bounds on extrinsic similarity, affine intrinsic similarity also allows us
  to begin uncovering the structure of the space of pre-trained encoders by defining
  an order over them.'

# Summary. An optional shortened abstract.
summary: ''

tags: []

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
venue: NeurIPS
links:
- name: URL
  url: https://arxiv.org/abs/2406.02329
---

Add the **full text** or **supplementary notes** for the publication here using Markdown formatting.
