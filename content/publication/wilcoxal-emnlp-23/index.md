---
title: Language Model Quality Correlates with Psychometric Predictive Power in Multiple
  Languages

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
- Ethan Wilcox
- Clara Meister
- Ryan Cotterell
- Tiago Pimentel
author_notes: []

date: '2023-12-01'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2025-07-15T16:36:01.449446Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types:
- '1'
publication: '*Proceedings of the 2023 Conference on Empirical Methods in Natural
  Language Processing*'
publication_short: ''

abstract: Surprisal theory (Hale, 2001; Levy, 2008) posits that a word’s reading time
  is proportional to its surprisal (i.e., to its negative log probability given the
  proceeding context). Since we are unable to access a word’s ground-truth probability,
  surprisal theory has been empirically tested using surprisal estimates from language
  models (LMs). Under the premise that surprisal theory holds, we would expect that
  higher quality language models provide more powerful predictors of human reading
  behavior---a conjecture we dub the quality--power (QP) hypothesis. Unfortunately,
  empirical support for the QP hypothesis is mixed. Some studies in English have found
  correlations between LM quality and predictive power, but other studies using Japanese
  data, as well as using larger English LMs, find no such correlations. In this work,
  we conduct a systematic crosslinguistic assessment of the QP hypothesis. We train
  LMs from scratch on small- and medium-sized datasets from 13 languages (across five
  language families) and assess their ability to predict eye tracking data. We find
  correlations between LM quality and power in eleven of these thirteen languages,
  suggesting that, within the range of model classes and sizes tested, better language
  models are indeed better predictors of human language processing behaviors.

# Summary. An optional shortened abstract.
summary: ''

tags: []

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
---

Add the **full text** or **supplementary notes** for the publication here using Markdown formatting.
