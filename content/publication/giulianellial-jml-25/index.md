---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Incremental Alternative Sampling as a Lens into the Temporal and Representational
  Resolution of Linguistic Prediction
subtitle: ''
summary: ''
authors:
- Mario Giulianelli
- Sarenne Wallbridge
- Ryan Cotterell
- Raquel Fernández
tags: []
categories: []
date: '2025-01-01'
lastmod: 2025-07-15T18:14:12+02:00
featured: true
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2025-07-15T16:17:29.550356Z'
publication_types:
- '1'
abstract: This study presents a new model of processing difficulty rooted in resource
  allocation theory, Incremental Alternative Sampling (IAS). Differential difficulty
  for a linguistic unit is estimated with respect to a set of plausible alternatives.
  Compared to a surprisal-based model, it prescribes a more efficient use of a comprehender's
  predicted continuations of partial linguistic stimuli thanks to (i) an expressive
  representation function that captures different levels of linguistic processing
  and (ii) the bootstrapping of long-horizon prediction error. Our results show that
  IAS estimates of processing difficulty, computed with autoregressive language models
  via Monte Carlo estimation, have greater predictive power than surprisal extracted
  from the same language models for most neural and behavioural responses under analysis—including
  reading times, event-related brain potentials, cloze and predictability judgements.
  Perhaps more importantly, IAS estimates provide insight into the nature of the predictive
  mechanisms that generate those responses during language comprehension. Variability
  in neural and behavioural responses is well explained by different combinations
  of the representational and temporal resolution of prediction. Processing difficulty
  calculated at varying representational domains reflects known relations to lexical,
  constructional, and structural levels of linguistic processing, and forecast horizons
  are determined by a combination of experimental task setup and naturalness of the
  stimulus. Beyond enriching psycholinguistic models, IAS can also provide insights
  into the information processing mechanisms of computational language models. Our
  analysis of next-word surprisal under the lenses of IAS reveals that, despite the
  metric's seemingly narrow focus on the upcoming word, language model surprisal implicitly
  captures anticipatory processing of multiple future lexical items.
publication: '*PsyArXiv*'
links:
- name: URL
  url: https://osf.io/preprints/psyarxiv/fhp84
---
