---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "If We Want AI to be Interpretable, We Need to Measure Interpretability"
event: 
event_url:
location: OAS J33
address: 
  street:
  city:
  region:
  postcode:
  country:
summary: 
abstract: 'AI tools are ubiquitous, but most users treat it as a black box: a handy tool that suggests purchases, flags spam, or autocompletes text. While researchers have presented explanations for making AI less of a black box, a lack of metrics make it hard to optimize explicitly for interpretability. Thus, I propose two metrics for interpretability suitable for unsupervised and supervised AI methods. For unsupervised topic models, I discuss our proposed "intruder" interpretability metric, how it contradicts the previous evaluation metric for topic models (perplexity), and discuss its uptake in the community over the last decade. For supervised question answering approaches, I show how human-computer cooperation can be measured and directly optimized by a multi-armed bandit approach to learn what kinds of explanations help specific users. I will then briefly discuss how similar setups can help users navigate information-rich domains like fact checking, translation, and web search.'
# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: 2023-01-11T14:00:00+02:00
date_end: 2023-01-11T15:00:00+02:00
all_day: false

# Schedule page publish date (NOT event date).
publishDate: 2023-01-11T16:05:00+02:00

authors: ["Jordan Boyd-Graber"]
tags: []

# Is this a featured event? (true/false)
featured: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

# Optional filename of your slides within your event's folder or a URL.
url_slides: 

url_code:
url_pdf: 
url_video:

# Markdown Slides (optional).
#   Associate this event with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

### Bio
Jordan Boyd-Graber is an associate professor in the University of Maryland's Computer Science Department, iSchool, UMIACS, and Language Science Center. He generally works on how humans can interact with AI tools, starting first with topic models, then translation, then negotiation, and most recently question answering. He and his students have won "best of" awards at NIPS (2009, 2015), NAACL (2016), and CoNLL (2015). Jordan also won the British Computing Society's 2015 Karen Sp√§rk Jones Award and a 2017 NSF CAREER award.
