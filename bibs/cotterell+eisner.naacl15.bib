@inproceedings{cotterell+eisner.naacl15, 
  title = {Penalized Expectation Propagation for Graphical Models over Strings},
  venue = {NAACL},
  year = {2015},
  anthology = {https://www.aclweb.org/anthology/N15-1094.pdf},
  author = {Cotterell, Ryan and 
	Eisner, Jason},
  booktitle = {Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month = {July},
  publisher = {Association for Computational Linguistics},
  address = {Denver, Colorado},
  pages = {932--942},
  abstract = {We present penalized expectation propagation (PEP), a novel algorithm for approximate inference in graphical models. Expectation propagation is a variant of loopy belief propagation that keeps messages tractable by projecting them back into a given family of functions. Our extension, PEP, uses a structuredsparsity penalty to encourage simple messages, thus balancing speed and accuracy. We specifically show how to instantiate PEP in the case of string-valued random variables, where we adaptively approximate finite-state distributions by variable-order n-gram models. On phonological inference problems, we obtain substantial speedup over previous related algorithms with no significant loss in accuracy.},
  url = {https://www.aclweb.org/anthology/N15-1094.pdf},
}
