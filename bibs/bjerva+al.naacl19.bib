@inproceedings{bjerva+al.naacl19, 
  title = {A Probabilistic Generative Model of Linguistic Typology},
  venue = {NAACL},
  year = {2019},
  arXiv = {https://arxiv.org/abs/1903.10950},
  anthology = {https://www.aclweb.org/anthology/N19-1156.pdf},
  author = {Bjerva, Johannes and 
	Kementchedjhieva, Yova and 
	Cotterell, Ryan and 
	Augenstein, Isabelle},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month = {June},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  volume = {1 (Long and Short Papers)},
  pages = {1529--1540},
  abstract = {In the principles-and-parameters framework, the structural features of languages depend on parameters that may be toggled on or off, with a single parameter often dictating the status of multiple features. The implied covariance between features inspires our probabilisation of this line of linguistic inquiry---we develop a generative model of language based on exponential-family matrix factorisation. By modelling all languages and features within the same architecture, we show how structural similarities between languages can be exploited to predict typological features with near-perfect accuracy, outperforming several baselines on the task of predicting held-out features. Furthermore, we show that language embeddings pre-trained on monolingual text allow for generalisation to unobserved languages. This finding has clear practical and also theoretical implications: the results confirm what linguists have hypothesised, i.e. that there are significant correlations between typological features and languages.},
  url = {https://www.aclweb.org/anthology/N19-1156.pdf},
}
