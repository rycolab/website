@inproceedings{vylomova+al.naacl19, 
  title = {Contextualization of Morphological Inflection},
  venue = {NAACL},
  year = {2019},
  arXiv = {https://arxiv.org/abs/1905.01420},
  anthology = {https://www.aclweb.org/anthology/N19-1203.pdf},
  author = {Vylomova, Ekaterina and 
	Cotterell, Ryan and 
	Baldwin, Timothy and 
	Cohn, Trevor and 
	Eisner, Jason},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month = {June},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  volume = {1 (Long and Short Papers)},
  pages = {2018--2024},
  abstract = {Critical to natural language generation is the production of correctly inflected text. In this paper, we isolate the task of predicting a fully inflected sentence from its partially lemmatized version. Unlike traditional morphological inflection or surface realization, our task input does not provide ''gold'' tags that specify what morphological features to realize on each lemmatized word; rather, such features must be inferred from sentential context. We develop a neural hybrid graphical model that explicitly reconstructs morphological features before predicting the inflected forms, and compare this to a system that directly predicts the inflected forms without relying on any morphological annotation. We experiment on several typologically diverse languages from the Universal Dependencies treebanks, showing the utility of incorporating linguistically-motivated latent variables into NLP models.},
  url = {https://www.aclweb.org/anthology/N19-1203.pdf},
}
